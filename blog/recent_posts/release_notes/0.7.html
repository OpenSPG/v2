<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-recent_posts/release_notes/0.7" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Version 0.7(2025-04-17) | KAG</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://openspg.github.io/v2/img/kag-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://openspg.github.io/v2/img/kag-social-card.jpg"><meta data-rh="true" property="og:url" content="https://openspg.github.io/v2/blog/recent_posts/release_notes/0.7"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Version 0.7(2025-04-17) | KAG"><meta data-rh="true" name="description" content="We are pleased to announce the official release of KAG 0.7. This update continues our commitment to enhancing the consistency, rigor, and precision of knowledge base-augmented reasoning in large language models, while introducing several significant new features."><meta data-rh="true" property="og:description" content="We are pleased to announce the official release of KAG 0.7. This update continues our commitment to enhancing the consistency, rigor, and precision of knowledge base-augmented reasoning in large language models, while introducing several significant new features."><link data-rh="true" rel="icon" href="/v2/img/favicon.png"><link data-rh="true" rel="canonical" href="https://openspg.github.io/v2/blog/recent_posts/release_notes/0.7"><link data-rh="true" rel="alternate" href="https://openspg.github.io/v2/blog/recent_posts/release_notes/0.7" hreflang="en"><link data-rh="true" rel="alternate" href="https://openspg.github.io/v2/blog/recent_posts/release_notes/0.7" hreflang="x-default"><link rel="stylesheet" href="/v2/assets/css/styles.6e1d16b3.css">
<script src="/v2/assets/js/runtime~main.a105f9f5.js" defer="defer"></script>
<script src="/v2/assets/js/main.0c5e9e2f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/v2/img/favicon.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/v2/"><div class="navbar__logo"><img src="/v2/img/favicon.png" alt="KAG Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/v2/img/favicon.png" alt="KAG Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">KAG</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/v2/docs_en">English</a></li><li><a class="dropdown__link" href="/v2/docs_ch">中文</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/v2/blog/category/design-philosophy">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/v2/blog/category/design-philosophy">Design Philosophy</a><button aria-label="Collapse sidebar category &#x27;Design Philosophy&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/v2/blog/category/white-paper">White Paper</a><button aria-label="Collapse sidebar category &#x27;White Paper&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/design_philosophy/white_paper/openspg">OpenSPG</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/v2/blog/category/technical-report">Technical Report</a><button aria-label="Collapse sidebar category &#x27;Technical Report&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/design_philosophy/technical_report/kag">KAG</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/design_philosophy/academic-paper">Academic Paper</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/v2/blog/category/software-introduction">Software Introduction</a><button aria-label="Collapse sidebar category &#x27;Software Introduction&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/design_philosophy/software_introduction/openspg">xxx</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/v2/blog/category/recent-posts">Recent Posts</a><button aria-label="Collapse sidebar category &#x27;Recent Posts&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/v2/blog/category/release-notes">Release Notes</a><button aria-label="Collapse sidebar category &#x27;Release Notes&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/v2/blog/recent_posts/release_notes/0.7">Version 0.7</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/recent_posts/release_notes/0.6">Version 0.6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/recent_posts/release_notes/0.5">Version 0.5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/recent_posts/release_notes/0.5.1">Version 0.5.1</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/v2/blog/category/technology-sharing">Technology Sharing</a><button aria-label="Collapse sidebar category &#x27;Technology Sharing&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/recent_posts/technology_sharing/kag_introduction_and_applications">KAG Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/v2/blog/recent_posts/technology_sharing/shang_hai_meetup">ShangHai Meetup</a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/v2/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/v2/blog/category/recent-posts"><span itemprop="name">Recent Posts</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/v2/blog/category/release-notes"><span itemprop="name">Release Notes</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Version 0.7</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Version 0.7(2025-04-17)</h1></header>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">English</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">中文</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><h1>1、Overview</h1><p>We are pleased to announce the official release of KAG 0.7. This update continues our commitment to enhancing the consistency, rigor, and precision of knowledge base-augmented reasoning in large language models, while introducing several significant new features.</p><p>Firstly, we have completely refactored the framework. The update adds support for both <strong>static</strong> and <strong>iterative</strong> task planning modes, along with a more rigorous hierarchical knowledge mechanism during the reasoning phase. Additionally, the new <strong>multi-executor</strong> extension mechanism and MCP protocol integration enable horizontal scaling of various symbolic solvers (such as <strong>math-executor</strong> and <strong>cypher-executor</strong>). These improvements not only help users quickly build knowledge-augmented applications to validate innovative ideas or domain-specific solutions, but also support continuous optimization of KAG Solver&#x27;s capabilities, thereby further enhancing reasoning rigor in vertical applications.</p><p>Secondly, we have comprehensively optimized the product experience: during the reasoning phase, we introduced dual modes &quot;<strong>Simple Mode</strong>&quot; and &quot;<strong>Deep Reasoning</strong>&quot; and added support for streaming reasoning output, significantly reducing user wait times. Particularly noteworthy is the introduction of the &quot;<strong>Lightweight Construction</strong>&quot; mode to better facilitate the large-scale business application of KAG and address the community&#x27;s most pressing concern about high knowledge construction costs. As shown in the KAG-V0.7LC column of Figure 1, we tested a hybrid approach where a 7B model handles knowledge construction and a 72B model handles knowledge-based question answering. The results on the two_wiki, hotpotqa, and musique benchmarks showed only minor declines of 1.20%, 1.90%, and 3.11%, respectively. However, the token cost（Refer to Aliyun Bailian pricing）for constructing a 100,000-character document was reduced from 4.63￥ to 0.479￥, a 89% reduction, which substantially saves users both time and financial costs. Additionally, we will release a KAG-specific extraction model and a distributed offline batch construction version, continuously compressing model size and improving construction throughput to achieve daily construction capabilities for millions or even tens of millions of documents in a single scenario.</p><p>Finally, to better promote business applications, technological advancement, and community exchange for knowledge-augmented LLMs, we have added an <strong>open_benchmark</strong> directory at the root level of the KAG repository. This directory includes reproduction methods for various datasets to help users replicate and improve KAG&#x27;s performance across different tasks. Moving forward, we will continue to expand with more vertical scenario task datasets to provide users with richer resources.</p><p>Beyond these framework and product optimizations, we&#x27;ve fixed several bugs in both reasoning and construction phases. This update uses Qwen2.5-72B as the base model, completing effect alignment across various RAG frameworks and partial KG datasets. For overall benchmark results, please refer to Figures 1 and 2, with detailed rankings available in the <strong>open_benchmark</strong> section.</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/png/358/1744814861206-111732b2-4407-431c-b642-8ebb77c635ea.png" alt="" class="img_ev3q"></p><p><em>Figure1. Performance of KAG V0.7 and baselines on Multi-hop QA benchmarks</em></p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/png/358/1744801826055-7e6985ad-d708-432d-9c57-7a0560ffef61.png" alt="" class="img_ev3q">_Figure2. Performance of KAG V0.7 and baselines(from OpenKG OneEval) on _<em>Knowledge based QA benchmarks</em></p><h1>2、Framework Enhancements</h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="21hybrid-static-dynamic-task-planning">2.1、Hybrid Static-Dynamic Task Planning<a href="#21hybrid-static-dynamic-task-planning" class="hash-link" aria-label="Direct link to 2.1、Hybrid Static-Dynamic Task Planning" title="Direct link to 2.1、Hybrid Static-Dynamic Task Planning">​</a></h3><p>This release introduces optimizations to the KAG-Solver framework implementation, providing more flexible architectural support for: &quot;Retrieval during reasoning&quot; workflows, Multi-scenario algorithm experimentation, LLM-symbolic engine integration (via MCP protocol).</p><p>The framework&#x27;s Static/Iterative Planner transforms complex problems into directed acyclic graphs (DAGs) of interconnected Executors, enabling step-by-step resolution based on dependency relationships. We&#x27;ve implemented built-in Pipeline support for both Static and Iterative Planners, including a predefined NaiveRAG Pipeline - offering developers customizable solver chaining capabilities while maintaining implementation flexibility.</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/jpeg/358/1742693417513-5838e6dd-ffef-4786-a936-bb5c271b4236.jpeg" alt="画板" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="22extensible-symbolic-solvers">2.2、Extensible Symbolic Solvers<a href="#22extensible-symbolic-solvers" class="hash-link" aria-label="Direct link to 2.2、Extensible Symbolic Solvers" title="Direct link to 2.2、Extensible Symbolic Solvers">​</a></h3><p>Leveraging LLM&#x27;s FunctionCall capability, we have optimized the design of symbolic solvers (Executors) to enable more rational solver matching during complex problem planning. This release includes built-in solvers such as <strong>kag_hybrid_executor</strong>, <strong>math_executor</strong>, and <strong>cypher_executor</strong>, while providing a flexible extension mechanism that allows developers to define custom solvers for personalized requirements.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="23optimized-retrievalreasoning-strategies">2.3、Optimized Retrieval/Reasoning Strategies<a href="#23optimized-retrievalreasoning-strategies" class="hash-link" aria-label="Direct link to 2.3、Optimized Retrieval/Reasoning Strategies" title="Direct link to 2.3、Optimized Retrieval/Reasoning Strategies">​</a></h3><p>Using the enhanced KAG-Solver framework, we have rewritten the logic of <strong>kag_hybrid_executor</strong> to implement a more rigorous knowledge layering mechanism during reasoning. Based on business requirements for knowledge precision and following KAG&#x27;s knowledge hierarchy definition, the system now sequentially retrieves three knowledge layers: <img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/77bb638a09212d94533113f88d8dcf4c.svg" alt="image" class="img_ev3q">(schema-constrained), <img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/9267a937e920fd15f3ff3c37c197ca56.svg" alt="image" class="img_ev3q"> (schema-free), and<img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/3d321e0c43bbe087db097c2242afe737.svg" alt="image" class="img_ev3q"> (raw context), subsequently performing reasoning to generate answers.</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/jpeg/358/1744867065033-837c17ce-eca7-4b3c-af75-b71329613170.jpeg" alt="画板" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="24mcp-protocol-integration">2.4、MCP Protocol Integration<a href="#24mcp-protocol-integration" class="hash-link" aria-label="Direct link to 2.4、MCP Protocol Integration" title="Direct link to 2.4、MCP Protocol Integration">​</a></h3><p>This KAG release achieves compatibility with the MCP protocol, enabling the incorporation of external data sources and symbolic solvers into the KAG framework via MCP. We have included a <strong>baidu_map_mcp</strong> example in the <strong>example</strong> directory for developers&#x27; reference.</p><h1>3、OpenBenchmark</h1><p>To better facilitate academic exchange and accelerate the adoption and technological advancement of large language models with external knowledge bases in enterprise settings, KAG has released more detailed benchmark reproduction steps in this version, along with open-sourcing all code and data. This will enable developers and researchers to easily reproduce and align results across various datasets.</p><p>For more accurate quantification of reasoning performance, we have adopted multiple evaluation metrics, including EM (Exact Match), F1, and LLM_Accuracy. In addition to existing datasets such as TwoWiki, Musique, and HotpotQA, this update introduces the OpenKG OneEval knowledge graph QA dataset (including AffairQA and PRQA) to evaluate the capabilities of both the <strong>cypher_executor</strong> and KAG&#x27;s default framework.</p><p>Building benchmarks is a time-consuming and complex endeavor. In future work, we will continue to expand benchmark datasets and provide domain-specific solutions to further enhance the accuracy, rigor, and consistency of large models in leveraging external knowledge. We warmly invite community members to collaborate with us in advancing the KAG framework&#x27;s capabilities and real-world applications across diverse tasks.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="31multi-hop-qa-dataset">3.1、Multi-hop QA Dataset<a href="#31multi-hop-qa-dataset" class="hash-link" aria-label="Direct link to 3.1、Multi-hop QA Dataset" title="Direct link to 3.1、Multi-hop QA Dataset">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="311benchmark">3.1.1、benchMark<a href="#311benchmark" class="hash-link" aria-label="Direct link to 3.1.1、benchMark" title="Direct link to 3.1.1、benchMark">​</a></h4><ul>
<li><strong>musique</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.033</td><td>0.074</td><td>0.083</td></tr><tr><td>Naive RAG</td><td>0.248</td><td>0.357</td><td>0.384</td></tr><tr><td>HippoRAGV2</td><td>0.289</td><td>0.404</td><td>0.452</td></tr><tr><td>PIKE-RAG</td><td><u>0.383</u></td><td>0.498</td><td><u>0.565</u></td></tr><tr><td>KAG-V0.6.1</td><td>0.363</td><td>0.481</td><td>0.547</td></tr><tr><td>KAG-V0.7LC</td><td>0.379</td><td><u>0.513</u></td><td>0.560</td></tr><tr><td>KAG-V0.7</td><td><strong>0.385</strong></td><td><strong>0.520</strong></td><td><strong>0.579</strong></td></tr></tbody></table><ul>
<li><strong>hotpotqa</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.223</td><td>0.313</td><td>0.342</td></tr><tr><td>Naive RAG</td><td>0.566</td><td>0.704</td><td>0.762</td></tr><tr><td>HippoRAGV2</td><td>0.557</td><td>0.694</td><td>0.807</td></tr><tr><td>PIKE-RAG</td><td>0.558</td><td>0.686</td><td>0.787</td></tr><tr><td>KAG-V0.6.1</td><td>0.599</td><td><u>0.745</u></td><td><u>0.841</u></td></tr><tr><td>KAG-V0.7LC</td><td><u>0.600</u></td><td><em>0.744</em></td><td><em>0.828</em></td></tr><tr><td>KAG-V0.7</td><td><strong>0.603</strong></td><td><strong>0.748</strong></td><td><strong>0.844</strong></td></tr></tbody></table><ul>
<li><strong>twowiki</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.199</td><td>0.310</td><td>0.382</td></tr><tr><td>Naive RAG</td><td>0.448</td><td>0.512</td><td>0.573</td></tr><tr><td>HippoRAGV2</td><td>0.542</td><td>0.618</td><td>0.684</td></tr><tr><td>PIKE-RAG</td><td>0.63</td><td>0.72</td><td>0.81</td></tr><tr><td>KAG-V0.6.1</td><td>0.666</td><td>0.755</td><td>0.811</td></tr><tr><td>KAG-V0.7LC</td><td><u>0.683</u></td><td><u>0.769</u></td><td><u>0.826</u></td></tr><tr><td>KAG-V0.7</td><td><strong>0.684</strong></td><td><strong>0.770</strong></td><td><strong>0.836</strong></td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="312params-for-each-method">3.1.2、params for each method<a href="#312params-for-each-method" class="hash-link" aria-label="Direct link to 3.1.2、params for each method" title="Direct link to 3.1.2、params for each method">​</a></h4><table><thead><tr><th><strong>Method</strong></th><th><strong>dataset</strong></th><th><strong>LLM(Build/Reason)</strong></th><th><strong>embed</strong></th><th><strong>param</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>10k docs、1k questions provided by HippoRAG</td><td>qwen2.5-72B</td><td>bge-m3</td><td>无</td></tr><tr><td>Naive RAG</td><td>same as above</td><td>qwen2.5-72B</td><td>bge-m3</td><td>num_docs: 10</td></tr><tr><td>HippoRAGV2</td><td>same as above</td><td>qwen2.5-72B</td><td>bge-m3</td><td>retrieval_top_k=200<br>linking_top_k=5<br>max_qa_steps=3<br>qa_top_k=5<br>graph_type=facts_and_sim_passage_node_unidirectional<br>embedding_batch_size=8</td></tr><tr><td>PIKE-RAG</td><td>same as above</td><td>qwen2.5-72B</td><td>bge-m3</td><td>tagging_llm_temperature: 0.7<br>qa_llm_temperature: 0.0<br>chunk_retrieve_k: 8<br>chunk_retrieve_score_threshold: 0.5<br>atom_retrieve_k: 16<br>atomic_retrieve_score_threshold: 0.2<br>max_num_question: 5<br>num_parallel: 5</td></tr><tr><td>KAG-V0.6.1</td><td>same as above</td><td>qwen2.5-72B</td><td>bge-m3</td><td>refer to the <code>kag_config.yaml</code> files in each subdirectory under <a href="https://github.com/OpenSPG/KAG/tree/v0.6/examples" target="_blank" rel="noopener noreferrer">https://github.com/OpenSPG/KAG/tree/v0.6/kag/examples</a>.</td></tr><tr><td>KAG-V0.7</td><td>same as above</td><td>qwen2.5-72B</td><td>bge-m3</td><td>refer to the <code>kag_config.yaml</code> files in each subdirectory under <a href="https://github.com/OpenSPG/KAG/tree/master/kag/open_benchmark" target="_blank" rel="noopener noreferrer">https://github.com/OpenSPG/KAG/tree/master/kag/open_benchmark</a></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="32structured-datasets">3.2、Structured Datasets<a href="#32structured-datasets" class="hash-link" aria-label="Direct link to 3.2、Structured Datasets" title="Direct link to 3.2、Structured Datasets">​</a></h3><p>PeopleRelQA (Person Relationship QA) and AffairQA (Government Affairs QA) are datasets provided by Alibaba Tianchi Competition and Zhejiang University respectively on the OpenKG OneEval benchmark. KAG delivers a streamlined implementation paradigm for vertical domain applications through its &quot;semantic modeling + structured graph construction + NL2Cypher retrieval&quot; approach. Moving forward, we will continue optimizing structured data QA performance by enhancing the integration between large language models and knowledge engines.</p><p>The OpenKG OneEval Benchmark primarily evaluates large language models&#x27; (LLMs) capabilities in comprehending and utilizing diverse knowledge domains. As documented in OpenKG&#x27;s official description, the benchmark employs relatively simple retrieval strategies that may introduce noise in recalled results, while simultaneously assessing LLMs&#x27; robustness when processing imperfect or redundant knowledge. KAG&#x27;s performance improvements in these scenarios stem from its effective retrieval strategies that ensure strong relevance between retrieved content and query intent.</p><p>In this update, KAG has validated its retrieval and reasoning capabilities on traditional knowledge graph tasks using the AffairQA and PRQA datasets. Future developments will focus on advancing schema standardization and reasoning framework alignment, along with releasing additional evaluation metrics to support broader application scenarios.</p><ul>
<li><strong>PeopleRelQA</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th><th><strong>Methodology</strong></th><th><strong>Metric Sources</strong></th></tr></thead><tbody><tr><td>deepseek-v3(OpenKG oneEval)</td><td>-</td><td>2.60%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>qwen2.5-72B(OpenKG oneEval)</td><td>-</td><td>2.50%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>GPT-4o(OpenKG oneEval)</td><td>-</td><td>3.20%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>QWQ-32B(OpenKG oneEval)</td><td>-</td><td>3.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>Grok 3(OpenKG oneEval)</td><td>-</td><td><u>4.70%</u></td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>KAG-V0.7</td><td><strong>45.5%</strong></td><td><strong>86.6%</strong></td><td><strong>84.8%</strong></td><td>Custom PRQA Pipeline with Cypher Solver Based on KAG Framework</td><td>Ant Group <br>KAG Team</td></tr></tbody></table><ul>
<li><strong>AffairQA</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th><th><strong>Methodology</strong></th><th><strong>Metric Sources</strong></th></tr></thead><tbody><tr><td>deepseek-v3</td><td>-</td><td>42.50%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>qwen2.5-72B</td><td>-</td><td>45.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>GPT-4o</td><td>-</td><td>41.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>QWQ-32B</td><td>-</td><td>45.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>Grok 3</td><td>-</td><td><u>45.50%</u></td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG WeChat</a></td></tr><tr><td>KAG-V0.7</td><td><strong>77.5%</strong></td><td><strong>83.1%</strong></td><td><strong>88.2%</strong></td><td>Custom PRQA Pipeline with Cypher Solver Based on KAG Framework</td><td>Ant Group <br>KAG Team</td></tr></tbody></table><h1>4、Product and platform optimization</h1><p>This update enhances the knowledge Q&amp;A product experience. Users can refer to the <a href="https://openspg.github.io/v2/docs_en" target="_blank" rel="noopener noreferrer">KAG User Manual</a> and access our demo files under the Quick Start -&gt; Product Mode section to reproduce the results shown in the following video.</p><ul>
<li><strong>Demo Of KAG Builder</strong></li>
</ul><iframe width="864" height="486" src="https://www.youtube.com/embed/ZocYwRLus6w" title="Demo Of KAG v0.7 Builder" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe><ul>
<li><strong>Demo Of KAG Solver</strong></li>
</ul><iframe width="864" height="486" src="https://www.youtube.com/embed/u51WYUcm3iM" title="Demo Of KAG v0.7 Solver" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe><h3 class="anchor anchorWithStickyNavbar_LWe7" id="41enhanced-qa-experience">4.1、Enhanced Q&amp;A Experience<a href="#41enhanced-qa-experience" class="hash-link" aria-label="Direct link to 4.1、Enhanced Q&amp;A Experience" title="Direct link to 4.1、Enhanced Q&amp;A Experience">​</a></h3><p>By optimizing the planning, execution, and generation capabilities of the KAG-Solver framework—leveraging Qwen2.5-72B and DeepSeek-V3 models—the system now achieves deep reasoning performance comparable to DeepSeek-R1. Three key features have been introduced:</p><ul>
<li>Streaming output for dynamic delivery of reasoning results</li>
<li>Auto-rendering of Markdown-formatted graph indices</li>
<li>Intelligent citation linking between generated content and source references</li>
</ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="42dual-mode-retrieval">4.2、Dual-Mode Retrieval<a href="#42dual-mode-retrieval" class="hash-link" aria-label="Direct link to 4.2、Dual-Mode Retrieval" title="Direct link to 4.2、Dual-Mode Retrieval">​</a></h3><p>The new Deep Reasoning Toggle allows users to balance answer accuracy against computational costs by enabling/disabling deep reasoning as needed. (Note: Web-augmented search is currently in testing—stay tuned for updates in future KAG releases.)</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="43indexing-infrastructure-upgrades">4.3、Indexing Infrastructure Upgrades<a href="#43indexing-infrastructure-upgrades" class="hash-link" aria-label="Direct link to 4.3、Indexing Infrastructure Upgrades" title="Direct link to 4.3、Indexing Infrastructure Upgrades">​</a></h3><ul>
<li><strong>Data Import</strong>
<ul>
<li>Expanded structured data support for CSV/ODPS/SLS sources</li>
<li>Optimized ingestion pipelines for improved usability</li>
</ul>
</li>
<li><strong>Hybrid Processing</strong>
<ul>
<li>Unified handling of structured and unstructured data</li>
<li>Enhanced task management via: Job scheduling、Execution logging、Data sampling for diagnostics</li>
</ul>
</li>
</ul><h1>5、Roadmap</h1><p>In upcoming iterations, We are continuously committed to enhancing the capability of large models to utilize external knowledge bases, achieving bidirectional enhancement and organic integration between large models and symbolic knowledge. This effort aims to consistently improve the factual accuracy, rigor, and coherence of reasoning and question-answering in specialized scenarios. We will also continue to release updates, constantly raising the upper limits of these capabilities and advancing their implementation in vertical domains.</p><h1>6、Acknowledgments</h1><p>This release addresses several issues in the hierarchical retrieval module, and we extend our sincere gratitude to the community developers who reported these problems.</p><p>The framework upgrade has received tremendous support from the following experts and colleagues, to whom we are deeply grateful:</p><ul>
<li><strong>Tongji University:</strong> Prof. Haofen Wang, Prof. Meng Wang</li>
<li><strong>Institute of Computing Technology, CAS:</strong> Dr. Long Bai</li>
<li><strong>Hunan KeChuang Information:</strong> R&amp;D Expert Ling Liu</li>
<li><strong>Open Source Community:</strong> Senior Developer Yunpeng Li</li>
<li><strong>Bank of Communications:</strong> R&amp;D Engineer Chenxing Gao</li>
</ul></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><h1>1、总体摘要</h1><p>我们正式发布KAG 0.7版本，本次更新旨在持续提升大模型利用知识库推理问答的一致性、严谨性和精准性，并引入了多项重要功能特性。</p><p>首先，我们对框架进行了全面重构。新增了对<strong>static</strong>和<strong>iterative</strong>两种任务规划模式的支持，同时实现了更严谨的推理阶段知识分层机制。此外，新增的<strong>multi-executor</strong>扩展机制以及MCP协议的接入，使用户能够横向扩展多种符号求解器（如<strong>math-executor</strong>和<strong>cypher-executor</strong>等）。这些改进不仅帮助用户快速搭建外挂知识库应用以验证创新想法或领域解决方案，还支持用户持续优化KAG Solver的能力，从而进一步提升垂直领域应用的推理严谨性。</p><p>其次，我们对产品体验进行了全面优化：在推理阶段新增&quot;<strong>简易模式</strong>&quot;和&quot;<strong>深度推理</strong>&quot;双模式，并支持流式推理输出，显著缩短了用户等待时间；特别值得关注的是，为更好的促进KAG的规模化业务应用，同时也回应社区最为关切的知识构建成本高的问题，本次发布提供了&quot;<strong>轻量级构建</strong>&quot;模式，如图1中KAG-V0.7LC列所示，我们测试了7B模型做知识构建、72B模型做知识问答的混合方案，在two_wiki、hotpotqa和musique三个榜单上的效果仅小幅下降1.20%、1.90%和3.11%，但十万字文档的构建token成本（参考阿里云百炼定价）从4.63￥减少到0.479￥, 降低89%，可大幅节约用户的时间和资金成本；我们还将发布KAG专用抽取模型和分布式离线批量构建版本，持续压缩模型尺寸提升构建吞吐，以实现单场景百万级甚至千万级文档的日构建能力。</p><p>最后，为了更好地推动大模型外挂知识库的业务应用、技术进步和社区交流，我们在KAG仓库的一级目录中新增了<strong>open_benchmark</strong>目录。该目录内置了各数据集的复现方法，帮助用户复现并提升KAG在各类任务上的效果。未来，我们将持续扩充更多垂直场景的任务数据集，为用户提供更丰富的资源。</p><p>除了上述框架和产品优化外，我们还修复了推理和构建阶段的若干Bug。本次更新以Qwen2.5-72B为基础模型，完成了各RAG框架及部分KG数据集的效果对齐。发布的整体榜单效果可参考图1和图2，榜单细节详见<strong>open_benchmark</strong>部分。</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/png/358/1744813542380-93fce754-dcb2-49a4-8584-310582da2107.png" alt="" class="img_ev3q"></p><p><em>图1 Performance of KAG V0.7 and baselines on Multi-hop QA benchmarks</em></p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/png/358/1744801826055-7e6985ad-d708-432d-9c57-7a0560ffef61.png" alt="" class="img_ev3q">_图2 Performance of KAG V0.7 and baselines(from OpenKG OneEval) on _<em>Knowledge based QA benchmarks</em></p><h1>2、框架优化</h1><h3 class="anchor anchorWithStickyNavbar_LWe7" id="21静态与动态结合的任务规划">2.1、静态与动态结合的任务规划<a href="#21静态与动态结合的任务规划" class="hash-link" aria-label="Direct link to 2.1、静态与动态结合的任务规划" title="Direct link to 2.1、静态与动态结合的任务规划">​</a></h3><p>本次发布对KAG-Solver框架的实现进行了优化，为“边推理边检索”、“多场景算法实验”以及“大模型与符号引擎结合（基于MCP协议）”提供了更加灵活的框架支持。</p><p>通过Static/Iterative Planner，复杂问题可以被转换为多个Executor之间的有向无环图（DAG），并根据依赖关系逐步求解。框架内置了Static/Iterative Planner的Pipeline实现，并预定义了NaiveRAG Pipeline，方便开发者灵活自定义求解链路。</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/jpeg/358/1742693417513-5838e6dd-ffef-4786-a936-bb5c271b4236.jpeg" alt="画板" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="22支持可扩展的符号求解器">2.2、支持可扩展的符号求解器<a href="#22支持可扩展的符号求解器" class="hash-link" aria-label="Direct link to 2.2、支持可扩展的符号求解器" title="Direct link to 2.2、支持可扩展的符号求解器">​</a></h3><p>基于LLM对FunctionCall的支持，我们优化了符号求解器（Executor）的设计，使其在复杂问题规划时能够更合理地匹配相应的求解器。本次更新内置了<strong>kag_hybrid_executor</strong>、<strong>math_executor</strong>、<strong>cypher_executor</strong>等求解器，同时提供了灵活的扩展机制，支持开发者定义新的求解器以满足个性化需求。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="23显性知识分层及分层检索推理策略优化">2.3、显性知识分层及分层检索、推理策略优化<a href="#23显性知识分层及分层检索推理策略优化" class="hash-link" aria-label="Direct link to 2.3、显性知识分层及分层检索、推理策略优化" title="Direct link to 2.3、显性知识分层及分层检索、推理策略优化">​</a></h3><p>基于优化后的KAG-Solver框架，我们重写了<strong>kag_hybrid_executor</strong>的逻辑，实现了更严谨的推理阶段知识分层机制。根据业务场景对知识精准性的要求，按照KAG的知识分层定义，依次检索三层知识：<img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/77bb638a09212d94533113f88d8dcf4c.svg" alt="image" class="img_ev3q">（基于schema-constraint）、<img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/9267a937e920fd15f3ff3c37c197ca56.svg" alt="image" class="img_ev3q">(基于schema-free）和<img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/__latex/3d321e0c43bbe087db097c2242afe737.svg" alt="image" class="img_ev3q">（原始上下文），并在此基础上进行推理生成答案。</p><p><img decoding="async" loading="lazy" src="https://intranetproxy.alipay.com/skylark/lark/0/2025/jpeg/358/1744867065033-837c17ce-eca7-4b3c-af75-b71329613170.jpeg" alt="画板" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="24拥抱mcp协议">2.4、拥抱MCP协议<a href="#24拥抱mcp协议" class="hash-link" aria-label="Direct link to 2.4、拥抱MCP协议" title="Direct link to 2.4、拥抱MCP协议">​</a></h3><p>KAG本次发版实现了对MCP协议的兼容，支持在KAG框架中通过MCP协议引入外部数据源和外部符号求解器。在<strong>example</strong>目录中，我们内置了<strong>baidu_map_mcp</strong>示例，供开发者参考使用。</p><h1>3、OpenBenchMark</h1><p>为更好地促进学术交流，加速大模型外挂知识库在企业中的落地和技术进步，KAG在本次发版中发布了更详细的Benchmark复现步骤，并开源了全部代码和数据。这将方便开发者和科研人员复现并对齐各数据集的结果。为了更准确地量化推理效果，我们采用了EM（Exact Match）、F1和LLM_Accuracy等多项评估指标。在原有TwoWiki、Musique、HotpotQA等数据集的基础上，本次更新新增了OpenKG OneEval知识图谱类问答数据集（如AffairQA和PRQA），以分别验证<strong>cypher_executor</strong>及KAG默认框架的能力。</p><p>搭建Benchmark是一个耗时且复杂的工程。在未来的工作中，我们将持续扩充更多Benchmark数据集，并提供针对不同领域的解决方案，进一步提升大模型利用外部知识的准确性、严谨性和一致性。我们也诚邀社区同仁共同参与，携手推进KAG框架在各类任务中的能力提升与实际应用落地。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="31多跳事实问答数据集">3.1、多跳事实问答数据集<a href="#31多跳事实问答数据集" class="hash-link" aria-label="Direct link to 3.1、多跳事实问答数据集" title="Direct link to 3.1、多跳事实问答数据集">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="311benchmark-1">3.1.1、benchMark<a href="#311benchmark-1" class="hash-link" aria-label="Direct link to 3.1.1、benchMark" title="Direct link to 3.1.1、benchMark">​</a></h4><ul>
<li><strong>musique</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.033</td><td>0.074</td><td>0.083</td></tr><tr><td>Naive RAG</td><td>0.248</td><td>0.357</td><td>0.384</td></tr><tr><td>HippoRAGV2</td><td>0.289</td><td>0.404</td><td>0.452</td></tr><tr><td>PIKE-RAG</td><td><u>0.383</u></td><td>0.498</td><td><u>0.565</u></td></tr><tr><td>KAG-V0.6.1</td><td>0.363</td><td>0.481</td><td>0.547</td></tr><tr><td>KAG-V0.7LC</td><td>0.379</td><td><u>0.513</u></td><td>0.560</td></tr><tr><td>KAG-V0.7</td><td><strong>0.385</strong></td><td><strong>0.520</strong></td><td><strong>0.579</strong></td></tr></tbody></table><ul>
<li><strong>hotpotqa</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.223</td><td>0.313</td><td>0.342</td></tr><tr><td>Naive RAG</td><td>0.566</td><td>0.704</td><td>0.762</td></tr><tr><td>HippoRAGV2</td><td>0.557</td><td>0.694</td><td>0.807</td></tr><tr><td>PIKE-RAG</td><td>0.558</td><td>0.686</td><td>0.787</td></tr><tr><td>KAG-V0.6.1</td><td><em>0.599</em></td><td><u>0.745</u></td><td><u>0.841</u></td></tr><tr><td>KAG-V0.7LC</td><td><u>0.600</u></td><td><em>0.744</em></td><td><em>0.828</em></td></tr><tr><td>KAG-V0.7</td><td><strong>0.603</strong></td><td><strong>0.748</strong></td><td><strong>0.844</strong></td></tr></tbody></table><ul>
<li><strong>twowiki</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>0.199</td><td>0.310</td><td>0.382</td></tr><tr><td>Naive RAG</td><td>0.448</td><td>0.512</td><td>0.573</td></tr><tr><td>HippoRAGV2</td><td>0.542</td><td>0.618</td><td>0.684</td></tr><tr><td>PIKE-RAG</td><td>0.63</td><td>0.72</td><td>0.81</td></tr><tr><td>KAG-V0.6.1</td><td><em>0.666</em></td><td><em>0.755</em></td><td><em>0.811</em></td></tr><tr><td>KAG-V0.7LC</td><td><u>0.683</u></td><td><u>0.769</u></td><td><u>0.826</u></td></tr><tr><td>KAG-V0.7</td><td><strong>0.684</strong></td><td><strong>0.770</strong></td><td><strong>0.836</strong></td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="312各种方法的参数配置">3.1.2、各种方法的参数配置<a href="#312各种方法的参数配置" class="hash-link" aria-label="Direct link to 3.1.2、各种方法的参数配置" title="Direct link to 3.1.2、各种方法的参数配置">​</a></h4><table><thead><tr><th><strong>Method</strong></th><th><strong>数据集</strong></th><th><strong>基模(构建/推理)</strong></th><th><strong>向量模型</strong></th><th><strong>参数设置</strong></th></tr></thead><tbody><tr><td>Naive Gen</td><td>hippoRAG 论文提供的1万 docs、1千 questions；</td><td>qwen2.5-72B</td><td>bge-m3</td><td>无</td></tr><tr><td>Naive RAG</td><td>同上</td><td>qwen2.5-72B</td><td>bge-m3</td><td>num_docs: 10</td></tr><tr><td>HippoRAGV2</td><td>同上</td><td>qwen2.5-72B</td><td>bge-m3</td><td>retrieval_top_k=200<br>linking_top_k=5<br>max_qa_steps=3<br>qa_top_k=5<br>graph_type=facts_and_sim_passage_node_unidirectional<br>embedding_batch_size=8</td></tr><tr><td>PIKE-RAG</td><td>同上</td><td>qwen2.5-72B</td><td>bge-m3</td><td>tagging_llm_temperature: 0.7<br>qa_llm_temperature: 0.0<br>chunk_retrieve_k: 8<br>chunk_retrieve_score_threshold: 0.5<br>atom_retrieve_k: 16<br>atomic_retrieve_score_threshold: 0.2<br>max_num_question: 5<br>num_parallel: 5</td></tr><tr><td>KAG-V0.6.1</td><td>同上</td><td>qwen2.5-72B</td><td>bge-m3</td><td>参见<a href="https://github.com/OpenSPG/KAG/tree/v0.6" target="_blank" rel="noopener noreferrer">https://github.com/OpenSPG/KAG/tree/v0.6</a> examples 各子目录的kag_config.yaml</td></tr><tr><td>KAG-V0.7LC</td><td>同上</td><td>构建：qwen2.5-7B <br>问答：qwen2.5-72B</td><td>bge-m3</td><td>参见<a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer">https://github.com/OpenSPG/KAG</a> open_benchmarks 各子目录kag_config.yaml</td></tr><tr><td>KAG-V0.7</td><td>同上</td><td>qwen2.5-72B</td><td>bge-m3</td><td>参见<a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer">https://github.com/OpenSPG/KAG</a> open_benchmarks 各子目录kag_config.yaml</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="32结构化数据集">3.2、结构化数据集<a href="#32结构化数据集" class="hash-link" aria-label="Direct link to 3.2、结构化数据集" title="Direct link to 3.2、结构化数据集">​</a></h3><p>PeopleRelQA（人物关系问答） 和 AffairQA(政务问答) 分别是OpenKG OneEval榜单上阿里云天池大赛和浙江大学提供的数据集。KAG通过“语义化建模 + 结构化构图 + NL2Cypher检索”的方式，为垂直领域应用提供了一个简洁的落地范式。未来，我们将围绕大模型与知识引擎的结合，持续优化结构化数据问答的效果。</p><p>OpenKG OneEval 榜单的重点在于评估大语言模型（LLM）对各类知识的理解与运用能力。参考OpenKG官方描述，该榜单在知识检索方面采用了较为简单的策略，该方法召回结果可能引入噪声，同时也评估LLM在面对不完美或冗余知识时的鲁棒性。KAG在这些场景中的指标提升得益于有效的检索策略保证了检索结果与问题之间的相关性。</p><p>本次更新中，KAG在AffairQA和PRQA数据集上验证了其针对传统知识图谱类任务的检索与推理能力。未来，KAG将进一步推动Schema的标准化和推理框架的对齐，并发布更多测试指标以支持更广泛的应用场景。</p><ul>
<li><strong>PeopleRelQA(人物关系问答)</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th><th><strong>方法论</strong></th><th><strong>指标来源</strong></th></tr></thead><tbody><tr><td>deepseek-v3(OpenKG oneEval)</td><td>-</td><td>2.60%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>qwen2.5-72B(OpenKG oneEval)</td><td>-</td><td>2.50%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>GPT-4o(OpenKG oneEval)</td><td>-</td><td>3.20%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>QWQ-32B(OpenKG oneEval)</td><td>-</td><td>3.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>Grok 3(OpenKG oneEval)</td><td>-</td><td><u>4.70%</u></td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>KAG-V0.7</td><td><strong>45.5%</strong></td><td><strong>86.6%</strong></td><td><strong>84.8%</strong></td><td>基于KAG 框架自定义AffairQA pipeline + cypher_solver</td><td>蚂蚁KAG 团队</td></tr></tbody></table><ul>
<li><strong>AffairQA（政务信息问答）</strong></li>
</ul><table><thead><tr><th><strong>Method</strong></th><th><strong>em</strong></th><th><strong>f1</strong></th><th><strong>llm_accuracy</strong></th><th><strong>方法论</strong></th><th><strong>指标提供者</strong></th></tr></thead><tbody><tr><td>deepseek-v3</td><td>-</td><td>42.50%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>qwen2.5-72B</td><td>-</td><td>45.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>GPT-4o</td><td>-</td><td>41.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>QWQ-32B</td><td>-</td><td>45.00%</td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>Grok 3</td><td>-</td><td><u>45.50%</u></td><td>-</td><td>Dense Retrieval + LLM Generation</td><td><a href="https://mp.weixin.qq.com/s/BeKah91_texXN3s1WAOcKg" target="_blank" rel="noopener noreferrer">OpenKG 公众号</a></td></tr><tr><td>KAG-V0.7</td><td><strong>77.5%</strong></td><td><strong>83.1%</strong></td><td><strong>88.2%</strong></td><td>基于KAG 框架自定义AffairQA pipeline</td><td>蚂蚁KAG 团队</td></tr></tbody></table><h1>4、产品及平台优化</h1><p>本次更新优化了知识问答的产品体验，用户可访问 <a href="https://openspg.github.io/v2/docs_ch" target="_blank" rel="noopener noreferrer">KAG 用户手册</a>，在快速开始-&gt;产品模式一节，获取我们的语料文件以复现以下视频中的结果。</p><ul>
<li><strong>知识构建Demo</strong></li>
</ul><iframe width="864" height="486" src="https://www.youtube.com/embed/GEDAxW1oiYE" title="知识构建KAG v0.7 Demo-研报构建" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe><ul>
<li><strong>知识问答Demo</strong></li>
</ul><iframe width="864" height="486" src="https://www.youtube.com/embed/XxXC-Fhln8o" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin"></iframe><h3 class="anchor anchorWithStickyNavbar_LWe7" id="41问答体验优化">4.1、问答体验优化<a href="#41问答体验优化" class="hash-link" aria-label="Direct link to 4.1、问答体验优化" title="Direct link to 4.1、问答体验优化">​</a></h3><p>通过优化KAG-Solver框架的规划、执行与生成功能，基于Qwen2.5-72B和DeepSeek-V3模型的应用，可实现与DeepSeek-R1相当的深度推理效果。在此基础上，产品新增三项能力：支持推理结果的流式动态输出、实现Markdown格式的图索引自动渲染，以及生成内容与原始文献引用的智能关联功能。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="42支持深度推理与普通检索">4.2、支持深度推理与普通检索<a href="#42支持深度推理与普通检索" class="hash-link" aria-label="Direct link to 4.2、支持深度推理与普通检索" title="Direct link to 4.2、支持深度推理与普通检索">​</a></h3><p>新增深度推理开关功能，用户可根据需求灵活启用或关闭，以平衡回答准确率与计算资源消耗；联网搜索的能力当前测试中，请关注KAG框架的后续版本更新。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="43索引构建能力完善">4.3、索引构建能力完善<a href="#43索引构建能力完善" class="hash-link" aria-label="Direct link to 4.3、索引构建能力完善" title="Direct link to 4.3、索引构建能力完善">​</a></h3><p>本次更新提升结构化数据导入能力，支持从 CSV、ODPS、SLS 等多种数据源导入结构化数据，优化数据加载流程，提升使用体验；可同时处理&quot;结构化&quot;和&quot;非结构化&quot;数据，满足多样性需求。同时，增强了知识构建的任务管理能力，提供任务调度、执行日志、数据抽样 等功能，便于问题追踪与分析。</p><h1>5、后续计划</h1><p>近期版本迭代中，我们持续致力于持续提升大模型利用外部知识库的能力，实现大模型与符号知识的双向增强和有机融合，不断提升专业场景推理问答的事实性、严谨性和一致性等，我们也将持续发布，不断提升能力的上限，不断推进垂直领域的落地。</p><h1>6、致谢</h1><p>本次发布修复了分层检索模块中的若干问题，在此特别感谢反馈这些问题的社区开发者们。</p><p>此次框架升级得到了以下专家和同仁的鼎力支持，我们深表感激：</p><ul>
<li>同济大学：王昊奋教授、王萌教授</li>
<li>中科院计算所：白龙博士</li>
<li>湖南科创信息：研发专家刘玲</li>
<li>开源社区：资深开发者李云鹏</li>
<li>交通银行：研发工程师高晨星</li>
</ul></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/OpenSPG/v2/tree/master/docs/recent_posts/release_notes/0.7.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/v2/blog/category/release-notes"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Release Notes</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/v2/blog/recent_posts/release_notes/0.6"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Version 0.6</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#21hybrid-static-dynamic-task-planning" class="table-of-contents__link toc-highlight">2.1、Hybrid Static-Dynamic Task Planning</a></li><li><a href="#22extensible-symbolic-solvers" class="table-of-contents__link toc-highlight">2.2、Extensible Symbolic Solvers</a></li><li><a href="#23optimized-retrievalreasoning-strategies" class="table-of-contents__link toc-highlight">2.3、Optimized Retrieval/Reasoning Strategies</a></li><li><a href="#24mcp-protocol-integration" class="table-of-contents__link toc-highlight">2.4、MCP Protocol Integration</a></li><li><a href="#31multi-hop-qa-dataset" class="table-of-contents__link toc-highlight">3.1、Multi-hop QA Dataset</a></li><li><a href="#32structured-datasets" class="table-of-contents__link toc-highlight">3.2、Structured Datasets</a></li><li><a href="#41enhanced-qa-experience" class="table-of-contents__link toc-highlight">4.1、Enhanced Q&amp;A Experience</a></li><li><a href="#42dual-mode-retrieval" class="table-of-contents__link toc-highlight">4.2、Dual-Mode Retrieval</a></li><li><a href="#43indexing-infrastructure-upgrades" class="table-of-contents__link toc-highlight">4.3、Indexing Infrastructure Upgrades</a></li><li><a href="#21静态与动态结合的任务规划" class="table-of-contents__link toc-highlight">2.1、静态与动态结合的任务规划</a></li><li><a href="#22支持可扩展的符号求解器" class="table-of-contents__link toc-highlight">2.2、支持可扩展的符号求解器</a></li><li><a href="#23显性知识分层及分层检索推理策略优化" class="table-of-contents__link toc-highlight">2.3、显性知识分层及分层检索、推理策略优化</a></li><li><a href="#24拥抱mcp协议" class="table-of-contents__link toc-highlight">2.4、拥抱MCP协议</a></li><li><a href="#31多跳事实问答数据集" class="table-of-contents__link toc-highlight">3.1、多跳事实问答数据集</a></li><li><a href="#32结构化数据集" class="table-of-contents__link toc-highlight">3.2、结构化数据集</a></li><li><a href="#41问答体验优化" class="table-of-contents__link toc-highlight">4.1、问答体验优化</a></li><li><a href="#42支持深度推理与普通检索" class="table-of-contents__link toc-highlight">4.2、支持深度推理与普通检索</a></li><li><a href="#43索引构建能力完善" class="table-of-contents__link toc-highlight">4.3、索引构建能力完善</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/v2/docs_en">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/OpenSPG/KAG/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">KAG<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/v2/blog/recent_posts/release_notes/0.6">Blog</a></li><li class="footer__item"><a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact US</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer" class="footer__link-item">zhengke.gzk@antgroup.com</a></li><li class="footer__item"><a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer" class="footer__link-item">leywar.liang@antgroup.com</a></li><li class="footer__item"><a href="https://github.com/OpenSPG/KAG" target="_blank" rel="noopener noreferrer" class="footer__link-item">mengshu.sms@antgroup.com</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 OpenSPG.</div></div></div></footer></div>
</body>
</html>